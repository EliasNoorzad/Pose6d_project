import torch.utils.data as data
from PIL import Image
import os
import numpy as np
import torchvision.transforms as transforms
import numpy.ma as ma
import yaml
import random
import copy
import cv2
from torch.utils.data import DataLoader
import matplotlib.pyplot as plt
import torch


###densefusion
class PoseDataset(data.Dataset):
    def __init__(self, mode, num_points, add_noise, root, noise_trans, refine):
        self.objlist = [1, 2, 4, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15]
        self.mode = mode
        self.num = num_points
        self.add_noise = add_noise
        self.root = root
        self.noise_trans = noise_trans
        self.refine = refine

        self.list_rgb = []
        self.list_depth = []
        self.list_label = []
        self.list_obj = []
        self.list_rank = []
        self.meta = {}
        self.pt = {}

        item_count = 0
        for item in self.objlist:
            txt_file = 'train.txt' if self.mode == 'train' else 'test.txt'
            with open(f'{self.root}/data/{item:02d}/{txt_file}') as f:
                lines = f.readlines()
            
            for line in lines:
                line = line.strip()
                item_count += 1
                if self.mode == 'test' and item_count % 10 != 0:
                    continue

                self.list_rgb.append(f'{self.root}/data/{item:02d}/rgb/{line}.png')
                self.list_depth.append(f'{self.root}/data/{item:02d}/depth/{line}.png')

                if self.mode == 'eval':
                    self.list_label.append(f'{self.root}/segnet_results/{item:02d}_label/{line}_label.png')
                else:
                    self.list_label.append(f'{self.root}/data/{item:02d}/mask/{line}.png')

                self.list_obj.append(item)
                self.list_rank.append(int(line))

            with open(f'{self.root}/data/{item:02d}/gt.yml', 'r') as meta_file:
                self.meta[item] = yaml.safe_load(meta_file)

            self.pt[item] = self.load_ply(f'{self.root}/models/obj_{item:02d}.ply')
            print(f"Object {item} loaded.")

        self.length = len(self.list_rgb)

        self.cam_cx = 325.26110
        self.cam_cy = 242.04899
        self.cam_fx = 572.41140
        self.cam_fy = 573.57043

        self.xmap = np.array([[j for i in range(640)] for j in range(480)])
        self.ymap = np.array([[i for i in range(640)] for j in range(480)])

        self.trancolor = transforms.ColorJitter(0.2, 0.2, 0.2, 0.05)
        self.norm = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
        self.border_list = [-1, 40, 80, 120, 160, 200, 240, 280, 320, 360, 400, 440, 480, 520, 560, 600, 640, 680]
        self.num_pt_mesh_large = 500
        self.num_pt_mesh_small = 500
        self.symmetry_obj_idx = [7, 8]
        self.target_size = 128

    def __getitem__(self, index):
        img = Image.open(self.list_rgb[index])
        depth = np.array(Image.open(self.list_depth[index]))
        label = np.array(Image.open(self.list_label[index]))
        obj = self.list_obj[index]
        rank = self.list_rank[index]

        meta = self.meta[obj][rank][0]

        mask_depth = ma.getmaskarray(ma.masked_not_equal(depth, 0))
        if self.mode == 'eval':
            mask_label = ma.getmaskarray(ma.masked_equal(label, 255))
        else:
            mask_label = ma.getmaskarray(ma.masked_equal(label, [255, 255, 255]))[:, :, 0]

        mask = mask_label * mask_depth

        if self.add_noise:
            img = self.trancolor(img)

        img = np.array(img)[:, :, :3]
        img = np.transpose(img, (2, 0, 1))
        img_masked = img

        rmin, rmax, cmin, cmax = self.get_bbox(meta['obj_bb'])
        img_masked = img_masked[:, rmin:rmax, cmin:cmax]

        # Process point cloud
        choose = mask[rmin:rmax, cmin:cmax].flatten().nonzero()[0]
        if len(choose) == 0:
            choose = np.zeros(self.num, dtype=np.int32)
        elif len(choose) > self.num:
            c_mask = np.zeros(len(choose), dtype=int)
            c_mask[:self.num] = 1
            np.random.shuffle(c_mask)
            choose = choose[c_mask.nonzero()]
        else:
            choose = np.pad(choose, (0, self.num - len(choose)), 'wrap')

        depth_masked = depth[rmin:rmax, cmin:cmax].flatten()[choose][:, np.newaxis].astype(np.float32)
        xmap_masked = self.xmap[rmin:rmax, cmin:cmax].flatten()[choose][:, np.newaxis].astype(np.float32)
        ymap_masked = self.ymap[rmin:rmax, cmin:cmax].flatten()[choose][:, np.newaxis].astype(np.float32)

        pt2 = depth_masked / 1.0  # cam_scale = 1.0
        pt0 = (ymap_masked - self.cam_cx) * pt2 / self.cam_fx
        pt1 = (xmap_masked - self.cam_cy) * pt2 / self.cam_fy

        cloud = np.concatenate((pt0, pt1, pt2), axis=1) / 1000.0

        if self.add_noise:
            add_t = np.array([random.uniform(-self.noise_trans, self.noise_trans) for _ in range(3)])
            cloud += add_t

        # Process model points
        model_points = self.pt[obj] / 1000.0
        dellist = random.sample(range(len(model_points)), len(model_points) - self.num_pt_mesh_small)
        model_points = np.delete(model_points, dellist, axis=0)

        target_r = np.resize(np.array(meta['cam_R_m2c']), (3, 3))
        target_t = np.array(meta['cam_t_m2c'])
        
        target = np.dot(model_points, target_r.T)
        if self.add_noise:
            target += target_t / 1000.0 + add_t
        else:
            target += target_t / 1000.0

        # Process image to fixed size
        h, w = img_masked.shape[1], img_masked.shape[2]
        if h > self.target_size or w > self.target_size:
            img_masked = np.transpose(img_masked, (1, 2, 0))
            img_masked = cv2.resize(img_masked, (self.target_size, self.target_size), interpolation=cv2.INTER_LINEAR)
            img_masked = np.transpose(img_masked, (2, 0, 1))
        else:
            pad_h = self.target_size - h
            pad_w = self.target_size - w
            pad_h_before = pad_h // 2
            pad_h_after = pad_h - pad_h_before
            pad_w_before = pad_w // 2
            pad_w_after = pad_w - pad_w_before
            img_masked = np.pad(img_masked, 
                               ((0, 0), (pad_h_before, pad_h_after), (pad_w_before, pad_w_after)), 
                               mode='constant', constant_values=0)

        # Convert to tensors
        img_tensor = self.norm(torch.from_numpy(img_masked.astype(np.float32)))
        cloud_tensor = torch.from_numpy(cloud.astype(np.float32))
        choose_tensor = torch.from_numpy(choose.astype(np.int32)).long()
        target_tensor = torch.from_numpy(target.astype(np.float32))
        model_points_tensor = torch.from_numpy(model_points.astype(np.float32))
        obj_idx_tensor = torch.LongTensor([self.objlist.index(obj)])

        return {
            'cloud': cloud_tensor,
            'choose': choose_tensor,
            'img': img_tensor,
            'target': target_tensor,
            'model_points': model_points_tensor,
            'obj_idx': obj_idx_tensor
        }

    def __len__(self):
        return self.length

    def get_bbox(self, bbox):
        rmin, rmax, cmin, cmax = bbox[1], bbox[1] + bbox[3], bbox[0], bbox[0] + bbox[2]
        rmin, rmax = max(0, rmin), min(479, rmax)
        cmin, cmax = max(0, cmin), min(639, cmax)

        r_b = rmax - rmin
        c_b = cmax - cmin

        for size in self.border_list:
            if r_b < size:
                r_b = size
                break
        for size in self.border_list:
            if c_b < size:
                c_b = size
                break

        center = [(rmin + rmax) // 2, (cmin + cmax) // 2]
        rmin = center[0] - r_b // 2
        rmax = center[0] + r_b // 2
        cmin = center[1] - c_b // 2
        cmax = center[1] + c_b // 2

        rmin = max(0, rmin)
        cmin = max(0, cmin)
        rmax = min(480, rmax)
        cmax = min(640, cmax)

        return rmin, rmax, cmin, cmax

    def load_ply(self, path):
        with open(path) as f:
            assert f.readline().strip() == "ply"
            f.readline()
            f.readline()
            N = int(f.readline().split()[-1])
            while f.readline().strip() != "end_header":
                continue
            pts = [np.float32(f.readline().split()[:3]) for _ in range(N)]
        return np.array(pts)

    def get_sym_list(self):
        return self.symmetry_obj_idx

    def get_num_points_mesh(self):
        return self.num_pt_mesh_large if self.refine else self.num_pt_mesh_small

def show_sample(img_tensor, cloud_tensor):
    # Unnormalize image
    img = img_tensor.numpy()
    img = np.transpose(img, (1, 2, 0))
    mean = np.array([0.485, 0.456, 0.406])
    std = np.array([0.229, 0.224, 0.225])
    img = std * img + mean
    img = np.clip(img, 0, 1)
    
    plt.figure(figsize=(10, 5))
    plt.subplot(1, 2, 1)
    plt.imshow(img)
    plt.title("Normalized Image")
    
    plt.subplot(1, 2, 2)
    cloud = cloud_tensor.numpy()
    plt.scatter(cloud[:, 0], cloud[:, 1], s=1)
    plt.title("Point Cloud Projection")
    plt.tight_layout()
    plt.show()

def test_dataset():
    root_path = "/content/drive/MyDrive/6D-pose-Dataset/Linemod_preprocessed"
    dataset = PoseDataset(mode='train', num_points=500, add_noise=True, root=root_path, noise_trans=0.03, refine=False)
    dataloader = DataLoader(dataset, batch_size=4, shuffle=True, num_workers=4)

    for i, batch in enumerate(dataloader):
        print(f"\nBatch {i}:")
        print(f"Cloud tensor shape: {batch['cloud'].shape}")
        print(f"Image tensor shape: {batch['img'].shape}")
        print(f"Object indices: {batch['obj_idx'].numpy().flatten()}")

        # Show first sample in batch
        show_sample(batch['img'][0], batch['cloud'][0])

        if i == 2:
            break

if __name__ == "__main__":
    test_dataset()
